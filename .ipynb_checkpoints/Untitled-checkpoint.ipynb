{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "<h3>Advanced Algorithmics</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Student Info</h3>\n",
    "Başar Turgut<br>\n",
    "B79636"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ranking will be based on the well known following facts:\n",
    "\n",
    "<li>Exponential functions grow faster than polynomial functions, which grow faster than\n",
    "logarithmic functions</li>\n",
    "\n",
    "<li>The base of a logarithm does not matter asymptotically, but the base of an exponential\n",
    "and the degree of a polynomial do matter.</li>\n",
    "\n",
    "<li>Stirling’s approximation for n! is useful for dealing with factorials asymptotically.</li>\n",
    "\n",
    "Most of the ranking is fairly straightforward. We will start finding out every possible f1 = Θ(f2) from our set of given functions.<br>\n",
    "\n",
    "n! = Θ((n+1)!) (We can show it using Stirling's approximation)<br>\n",
    "\n",
    "$2^{2^{n+1}} = Θ(2^{2^{n}})$<br>\n",
    "\n",
    "Proof:<br>\n",
    "$2^{n+1} = Θ(2^{n}) \\Rightarrow 2^{2^{n+1}} = Θ(2^{2^{n}})$\n",
    "\n",
    "$lg*n = Θ(ln(n))$\n",
    "\n",
    "We will order the rest of the functions and we can use one of each function for each same growth order group we found. While << indicates RHS has faster growing speed than RHS, \",\" seperated groups have the same growth order and $n\\rightarrow0$.<br>\n",
    "\n",
    "$1 << lg*n,ln(n) << n << n.lg*n << n^{2} << n^{3} << 2^{lg*n} << 2^{n} << e^{n} << 2^{2^{n}}, 2^{2^{n+1}} << n!, (n+1)!$<br>\n",
    "\n",
    "So, we can decide that where we need to put factorials using stirling approximation. We can use the approximation to find $lg*(n!)$\n",
    "\n",
    "$n! \\sim \\frac{n^{n}}{e^{n}}\\sqrt{2\\pi n}$<br>\n",
    "\n",
    "We can apply lg* to the each side of the approximation.<br>\n",
    "\n",
    "$lg*(n!) \\sim n.lg*(n) - n 1/2.lg*(n) + 1/2.lg*(2\\pi) + c \\Rightarrow lg*(n) = Θ(n.lg*n)$<br>\n",
    "\n",
    "So our final ranking result has been shown below:<br>\n",
    "$1 << lg*n,ln(n) << n << n.lg*n,lg*(n!) << n^{2} << n^{3} << 2^{lg*n} << 2^{n} << e^{n} << 2^{2^{n}}, 2^{2^{n+1}} << n!, (n+1)!$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, we need to import needed libraries to our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for imports\n",
    "import numpy\n",
    "import random\n",
    "import sys\n",
    "import copy\n",
    "from random import randint\n",
    "import time\n",
    "from scipy import interp, arange, exp\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used the pseudo code of binary search that described in rosettacode. Used pseudo codes as base for python implementation are having shown below.\n",
    "\n",
    "### Binary Search Pseudocode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "  // initially called with low = 0, high = N-1\n",
    "  BinarySearch(A[0..N-1], value, low, high) {\n",
    "      // invariants: value > A[i] for all i < low\n",
    "                     value < A[i] for all i > high\n",
    "      if (high < low)\n",
    "          return not_found // value would be inserted at index \"low\"\n",
    "      mid = (low + high) / 2\n",
    "      if (A[mid] > value)\n",
    "          return BinarySearch(A, value, low, mid-1)\n",
    "      else if (A[mid] < value)\n",
    "          return BinarySearch(A, value, mid+1, high)\n",
    "      else\n",
    "          return mid\n",
    "  }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of algorithm depends on pseudocode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Code for binary search\n",
    "def binarySearch(A, value, low, high):\n",
    "    if (high < low):\n",
    "        return -1\n",
    "    mid = (low + high) / 2\n",
    "    if (A[mid] > value):\n",
    "        return binarySearch(A, value, low, mid-1)\n",
    "    elif (A[mid] < value):\n",
    "        return binarySearch(A, value, mid+1, high)\n",
    "    else:\n",
    "        return mid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above part, our implementation works in a recursive way. We consider that initial low and high will be 0 and n-1, if we say n is the length of A input vector. In addition, input vector A will be sorted. In this context, we will check if system could not find any solution and reached any leaf. It is one of base conditions to break recursion. If algorithm works, we calculate a new mid point and check if it is the element we look for and returns mid index. If element with mid index is not the solution, we compare it with our value to find which side possibly contains value we look for. Then, we call method again with suitable parameters to search related subset of vector.<br>\n",
    "\n",
    "We will use a range of 1:100 to test how many times we can run our algorithm in 60 miliseconds. I know, it should be 1 minute as given the question but it was hard to run 1min with 1:100 range and 10 repeat. We are using 1:100 range to make numbers high as possible. It will make easier to distinguish and will have an understandable plot. We are also running tests 10 times and applying mean to find results. It will smooth our results.\n",
    "\n",
    "Test code and plot of results are having shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for experiment\n",
    "print \"N Test Set\"\n",
    "ns = range(1,100) # N values\n",
    "print ns\n",
    "for n in ns:\n",
    "    inputSet = [randint(0,sys.maxint) for p in range(0,n)]\n",
    "    inputSet.sort();\n",
    "    sumRun = 0\n",
    "    for j in range(1,10):\n",
    "        timeSpend = 0\n",
    "        initialTime = current_milli_time();\n",
    "        i = 0\n",
    "        while timeSpend < 60:\n",
    "            binarySearch(inputSet, 15, 1, len(inputSet)-1)\n",
    "            timeSpend = current_milli_time() - initialTime\n",
    "            i = i + 1\n",
    "        sumRun = sumRun + i\n",
    "    sumRun = sumRun / 50\n",
    "    print str(n) + \" \" + str(sumRun)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"files/plot3.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our runs goes down for when N increase. Binary search has upper bound of logn ($O(log(n))$). We tried to visualize it using $a/log(n) + b$ formula. Because, our results are number of runs for fixed time intervals. We applied different a and b values to bound our results. According to results, we should increase our repeating number for same experiment, because of the shape of our plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T(n) = 7T(n/3) + n^{2}$\n",
    "\n",
    "As we see above, we have a reccurrence. We can apply master method to solve it.\n",
    "\n",
    "According to master method basics, we should find a, b, f(n) for our relation. ($T(n) = aT(n/b) + f(n)$)\n",
    "\n",
    "a = 7, b = 3 and $f(n) = n^{2}$\n",
    "\n",
    "We need to find $n^{\\log_{b}{a}}$ and compare with c from $f(n) = n^{c}$.\n",
    "\n",
    "$n^{\\log_{b}{a}} = n^{\\log_{3}{7}} \\sim n^{1.77}$\n",
    "\n",
    "$n^{2} = n^{c} \\Rightarrow c = 2$\n",
    "\n",
    "$\\Rightarrow c > 1.77$, it is case 3.\n",
    "\n",
    "We should check regularity condition.\n",
    "\n",
    "$af(n/b) \\leqslant kf(n), k < 1 \\Rightarrow 2(n^{2}/4) \\leqslant kn^{2}, k = 0.5$ \n",
    "\n",
    "This condition holds. Then, \n",
    "\n",
    "$T(n) = \\Theta(f(n)) = \\Theta(n^{2})$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see binary search is always goes with n/2 as main factor. So, we can define the reccurrence relation like below. Ofcourse because of 1 comparison, we should add 1.\n",
    "\n",
    "$T(n) = T(n/2) + 1$\n",
    "\n",
    "We have found a reccurrence relation. We can apply master method to solve it.\n",
    "\n",
    "According to master method basics, we should find a, b, f(n) for our relation. ($T(n) = aT(n/b) + f(n)$)\n",
    "\n",
    "a = 1, b = 2 and $f(n) = 1$\n",
    "\n",
    "We need to find $n^{\\log_{b}{a}}$ and compare with f(n).\n",
    "\n",
    "$n^{\\log_{b}{a}} = n^{\\log_{2}{1}} = n^{0} = 1$\n",
    "\n",
    "Because $f(n) = \\Theta(1)$, it is case 2.\n",
    "\n",
    "Then, \n",
    "\n",
    "$f(n) = \\Theta(n^{c}(\\log_{}{n})^k) \\Rightarrow k=0$\n",
    "\n",
    "$\\Rightarrow T(n) = \\Theta(n^{\\log_{b}{a}}(\\log_{}{n})^{k+1}) = \\Theta(\\log_{}{n})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse effects of caching possible, we will use a suitable test case like factorial or fibonacci series. For our exercise, we will use our fibonacci implementation to compare effects of caching(memoization). <br>\n",
    "\n",
    "We will run set of experiments on our implementation without any memoization and memoization. We implemented two method for fibonacci with caching enabled and disabled. To see the effects well, we will calculate every fibonacci from 1 to 30 and 30 to 90. 1 to 30 range is used with step count 1 and 30 to 90 is used with step count 10 to see effects of picking some inputs far from cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "current_milli_time = lambda: int(round(time.time() * 1000))\n",
    "def fibo(n):\n",
    "    if n == 0: return 0\n",
    "    elif n == 1: return 1\n",
    "    else: return fibo(n-1)+fibo(n-2)\n",
    "fibo_memo = {}\n",
    "def fibo_with_caching(n):\n",
    "    if n == 0: return 0\n",
    "    elif n == 1: return 1\n",
    "    else: \n",
    "        if n not in fibo_memo:\n",
    "            fibo_memo[n] = fibo_with_caching(n-1)+fibo_with_caching(n-2)\n",
    "        return fibo_memo[n]\n",
    "fwc = 0\n",
    "fwoc = 0\n",
    "for i in range(1,30):\n",
    "    initialTime = current_milli_time();\n",
    "    fibo_with_caching(i)\n",
    "    fwc = current_milli_time() - initialTime\n",
    "    initialTime = current_milli_time()\n",
    "    fibo(i)\n",
    "    fwoc = current_milli_time() - initialTime\n",
    "    print str(i) + \" \" + str(fwc) + \" \" + str(fwoc);\n",
    "for i in range(30,100, 10):\n",
    "    initialTime = current_milli_time();\n",
    "    fibo_with_caching(i)\n",
    "    fwc = current_milli_time() - initialTime\n",
    "    initialTime = current_milli_time()\n",
    "    #fibo(i)\n",
    "    fwoc = current_milli_time() - initialTime\n",
    "    print str(i) + \" \" + str(fwc) + \" \" + str(fwoc);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"files/plot1.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, performance of implementation for caching is super fast. Because, it only do 1 multiplication for any calculation. Rest of the calculations are done by cache call. Still there is some drawbacks, if we keep everything in cache, it will use memory to store those. We can improve our caching solution by adding a maximum limit, and removing the oldest items from cache if cache is full in a regular basis.\n",
    "\n",
    "If we calculate some different values those are not close to the cached range. In this case, we can easily see that the performance of algorithm goes down. Because, if we pick any value much far from the cached values(for our case it is), will cost more time. Because we will do more calculations depending on unknown elements of serie. If we pick something near cached range, we can use cached values to improve calculation costs.\n",
    "\n",
    "Somehow our results for caching algorithm is way too perfect. This will be asked to the TA of the class and will be discussed about. In addition, i did not run normal fibonacci algorithm for tests bigger than 30, because it was consuming too much time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/1988804/what-is-memoization-and-how-can-i-use-it-in-python<br>\n",
    "https://www.youtube.com/watch?v=6CX7s7JnXs0<br>\n",
    "https://en.wikipedia.org/wiki/Stirling%27s_approximation<br>\n",
    "https://stackoverflow.com/questions/2095395/is-logn-%CE%98n-logn<br>\n",
    "https://en.wikipedia.org/wiki/Time_complexity<br>\n",
    "http://www.comp.nus.edu.sg/~cs1102s/assignments/assignment_01_solution.pdf<br>\n",
    "https://en.wikipedia.org/wiki/Master_theorem#Case_2_example<br>\n",
    "http://codeblab.com/wp-content/uploads/2009/09/DualPivotQuicksort.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
